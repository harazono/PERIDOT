# 共通設定
"""
書き換える項目は以下の通り：
- input_file
- primer3_config_path
- primer3_config_with_probe_path
- margin_size
- threshold
"""
input_file                       = "SRR10238608.fasta"
input_file_base                  = input_file.split(".")[0]
primer3_config_path              = "./primer3_config/normal_config"
primer3_config_with_probe_path   = "./primer3_config/normal_config_with_probe"
primer3_config_display_name      = "normal_config"
taxon_ids                        = "taxon_ids_to_be_ignored.txt"
target_db_filepath               = "target_dbs.txt"
ngs_read_part_size               = 63
lr_tuple_part_size               = 1
blast_check_part_size            = 1
margin_size                      = 50
threshold                        = 2500 #リードのカバレッジと分割数に応じて適宜変える←seqkit statsで調べてから動的に変える？面倒かも？
threshold_zfill                  = str(threshold).zfill(4)
home                             = "/home/harazono"
program_path                     = f"{home}/Species_specific_DNA_marker/swordfish_test/swordfish"
primer3_result_parser_path       = f"{program_path}/util/primer3_result_parser.py"
discard_primers_path             = f"{program_path}/util/discard_trapped_primers.py"
concatinate_primers_path         = f"{program_path}/util/chose_represantive.py"
redesign_primers_with_probe_path = f"{program_path}/util/redesign_primers_with_probe.py"
extract_amplicon_path            = f"{program_path}/search_primer/target/release/extract_PCR_target_region"
soybean_sequence_dir             = f"{home}/Species_specific_DNA_marker/SRR23506414/split/*/*.nhr"



ngs_read_indice = [str(i).zfill(3) for i in range(1, ngs_read_part_size + 1)]
lr_tuple_indice = [str(i).zfill(3) for i in range(1, lr_tuple_part_size + 1)]
blast_check_indice = [str(i).zfill(3) for i in range(1, blast_check_part_size + 1)]

def load_target_dbs():
    with open(target_db_filepath) as f:
        return [line.strip() for line in f]
tgt_db_name_fullpath = load_target_dbs()
tgt_db_names         = [x.split("/")[-1] for x in tgt_db_name_fullpath]
dbname2fullpath_dict = {x.split("/")[-1]:x for x in tgt_db_name_fullpath}


target_db_basename = ["16S_ribosomal_RNA", "18S_fungal_sequences", "28S_fungal_sequences", "Betacoronavirus.00", "Betacoronavirus.01", "Betacoronavirus.02", "Betacoronavirus.03", "Betacoronavirus.04", "Betacoronavirus.05", "Betacoronavirus.06", "Betacoronavirus.07", "Betacoronavirus.08", "Betacoronavirus.09", "Betacoronavirus.10", "Betacoronavirus.11", "Betacoronavirus.12", "Betacoronavirus.13", "Betacoronavirus.14", "Betacoronavirus.15", "GCF_000001405.39_top_level.00", "GCF_000001405.39_top_level.01", "GCF_000001635.27_top_level.00", "GCF_000001635.27_top_level.01", "ITS_RefSeq_Fungi", "ITS_eukaryote_sequences", "LSU_eukaryote_rRNA", "LSU_prokaryote_rRNA", "SSU_eukaryote_rRNA", "mito", "nt.000", "nt.001", "nt.002", "nt.003", "nt.004", "nt.005", "nt.006", "nt.007", "nt.008", "nt.009", "nt.010", "nt.011", "nt.012", "nt.013", "nt.014", "nt.015", "nt.016", "nt.017", "nt.018", "nt.019", "nt.020", "nt.021", "nt.022", "nt.023", "nt.024", "nt.025", "nt.026", "nt.027", "nt.028", "nt.029", "nt.030", "nt.031", "nt.032", "nt.033", "nt.034", "nt.035", "nt.036", "nt.037", "nt.038", "nt.039", "nt.040", "nt.041", "nt.042", "nt.043", "nt.044", "nt.045", "nt.046", "nt.047", "nt.048", "nt.049", "nt.050", "nt.051", "nt.052", "nt.053", "nt.054", "nt.055", "nt.056", "nt.057", "nt.058", "nt.059", "nt.060", "nt.061", "nt.062", "nt.063", "nt.064", "nt.065", "nt.066", "nt.067", "nt.068", "nt.069", "nt.070", "nt.071", "nt.072", "nt.073", "nt.074", "nt.075", "nt.076", "nt.077", "nt.078", "nt.079", "nt.080", "nt.081", "nt.082", "nt.083", "nt.084", "nt.085", "nt.086", "nt.087", "nt.088", "nt.089", "nt.090", "nt.091", "nt.092", "nt.093", "nt.094", "nt.095", "nt.096", "nt.097", "nt.098", "nt.099", "nt.100", "nt.101", "nt.102", "nt.103", "nt.104", "nt.105", "nt.106", "nt.107", "nt.108", "nt.109", "nt.110", "nt.111", "nt.112", "nt.113", "nt.114", "nt.115", "nt.116", "nt.117", "nt.118", "nt.119", "nt.120", "nt.121", "nt.122", "nt.123", "nt.124", "nt.125", "nt.126", "nt.127", "pdbnt", "ref_euk_rep_genomes.000", "ref_euk_rep_genomes.001", "ref_euk_rep_genomes.002", "ref_euk_rep_genomes.003", "ref_euk_rep_genomes.004", "ref_euk_rep_genomes.005", "ref_euk_rep_genomes.006", "ref_euk_rep_genomes.007", "ref_euk_rep_genomes.008", "ref_euk_rep_genomes.009", "ref_euk_rep_genomes.010", "ref_euk_rep_genomes.011", "ref_euk_rep_genomes.012", "ref_euk_rep_genomes.013", "ref_euk_rep_genomes.014", "ref_euk_rep_genomes.015", "ref_euk_rep_genomes.016", "ref_euk_rep_genomes.017", "ref_euk_rep_genomes.018", "ref_euk_rep_genomes.019", "ref_euk_rep_genomes.020", "ref_euk_rep_genomes.021", "ref_euk_rep_genomes.022", "ref_euk_rep_genomes.023", "ref_euk_rep_genomes.024", "ref_euk_rep_genomes.025", "ref_euk_rep_genomes.026", "ref_euk_rep_genomes.027", "ref_euk_rep_genomes.028", "ref_euk_rep_genomes.029", "ref_euk_rep_genomes.030", "ref_euk_rep_genomes.031", "ref_euk_rep_genomes.032", "ref_euk_rep_genomes.033", "ref_euk_rep_genomes.034", "ref_euk_rep_genomes.035", "ref_euk_rep_genomes.036", "ref_euk_rep_genomes.037", "ref_euk_rep_genomes.038", "ref_euk_rep_genomes.039", "ref_euk_rep_genomes.040", "ref_euk_rep_genomes.041", "ref_euk_rep_genomes.042", "ref_euk_rep_genomes.043", "ref_euk_rep_genomes.044", "ref_euk_rep_genomes.045", "ref_euk_rep_genomes.046", "ref_euk_rep_genomes.047", "ref_euk_rep_genomes.048", "ref_euk_rep_genomes.049", "ref_euk_rep_genomes.050", "ref_euk_rep_genomes.051", "ref_euk_rep_genomes.052", "ref_euk_rep_genomes.053", "ref_euk_rep_genomes.054", "ref_euk_rep_genomes.055", "ref_euk_rep_genomes.056", "ref_euk_rep_genomes.057", "ref_euk_rep_genomes.058", "ref_euk_rep_genomes.059", "ref_euk_rep_genomes.060", "ref_euk_rep_genomes.061", "ref_euk_rep_genomes.062", "ref_euk_rep_genomes.063", "ref_euk_rep_genomes.064", "ref_euk_rep_genomes.065", "ref_euk_rep_genomes.066", "ref_euk_rep_genomes.067", "ref_euk_rep_genomes.068", "ref_euk_rep_genomes.069", "ref_euk_rep_genomes.070", "ref_euk_rep_genomes.071", "ref_euk_rep_genomes.072", "ref_euk_rep_genomes.073", "ref_euk_rep_genomes.074", "ref_euk_rep_genomes.075", "ref_euk_rep_genomes.076", "ref_euk_rep_genomes.077", "ref_euk_rep_genomes.078", "ref_euk_rep_genomes.079", "ref_euk_rep_genomes.080", "ref_euk_rep_genomes.081", "ref_euk_rep_genomes.082", "ref_euk_rep_genomes.083", "ref_euk_rep_genomes.084", "ref_euk_rep_genomes.085", "ref_euk_rep_genomes.086", "ref_euk_rep_genomes.087", "ref_euk_rep_genomes.088", "ref_euk_rep_genomes.089", "ref_euk_rep_genomes.090", "ref_euk_rep_genomes.091", "ref_euk_rep_genomes.092", "ref_euk_rep_genomes.093", "ref_euk_rep_genomes.094", "ref_euk_rep_genomes.095", "ref_euk_rep_genomes.096", "ref_euk_rep_genomes.097", "ref_euk_rep_genomes.098", "ref_euk_rep_genomes.099", "ref_euk_rep_genomes.100", "ref_euk_rep_genomes.101", "ref_euk_rep_genomes.102", "ref_euk_rep_genomes.103", "ref_euk_rep_genomes.104", "ref_prok_rep_genomes.00", "ref_prok_rep_genomes.01", "ref_prok_rep_genomes.02", "ref_prok_rep_genomes.03", "ref_prok_rep_genomes.04", "ref_prok_rep_genomes.05", "ref_prok_rep_genomes.06", "ref_prok_rep_genomes.07", "ref_prok_rep_genomes.08", "ref_prok_rep_genomes.09", "ref_prok_rep_genomes.10", "ref_prok_rep_genomes.11", "ref_prok_rep_genomes.12", "ref_prok_rep_genomes.13", "ref_prok_rep_genomes.14", "ref_prok_rep_genomes.15", "ref_prok_rep_genomes.16", "ref_prok_rep_genomes.17", "ref_viroids_rep_genomes", "ref_viruses_rep_genomes", "refseq_rna.00", "refseq_rna.01", "refseq_rna.02", "refseq_rna.03", "refseq_rna.04", "refseq_rna.05", "refseq_rna.06", "refseq_rna.07", "refseq_rna.08", "refseq_select_rna", "tsa_nt.00", "tsa_nt.01", "tsa_nt.02", "tsa_nt.03", ]
# target_db_basename = ["refseq_rna.04"]
# lr_tuple_indice = ["001"]

rule all:
    input:
        # expand(f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_json/{threshold_zfill}/{threshold_zfill}_{{index}}.json", index = lr_tuple_indice),
        # expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{{index}}/non_cross_reactive_primers.txt",index=blast_check_indice),
        # expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{{index}}/non_cross_reactive_primers.txt",index=["012"]),
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/non_cross_reactive_primers.tsv",
        f"results_of_extraction_of_amplicon_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/amplicon_2000.fasta",

rule split_reads:
    # ToDo
    # メモリ使用量、要求スレッド数のチューニング
    input:
        input_file
    output:
        expand(f"ngs_reads/{input_file_base}.part_{{sample}}.fasta", sample=ngs_read_indice),
        log_file = f"log/rule_split_reads.log"
    params:
        ngs_read_part_size=ngs_read_part_size,
        home=home
    resources:
        mem_mb=1000*32
    threads: 8
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "split_reads,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        export PATH={home}/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH={home}/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p ngs_reads
        echo "Splitting reads started: $(date)" > {output.log_file}
        seqkit split -j 8 -p {ngs_read_part_size} {input} --out-dir ngs_reads
        echo "Splitting reads end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """


rule count_lr_tuple:
    # ToDo
    # メモリ使用量、要求スレッド数のチューニング
    # count_lr_tupleをscripts以下に置く
    # count_lr_tupleの引数をチェックする
    # mergin sizeとthresholdは、レポートファイルに書き出すことを考えるとSnakemakeの変数で持っておきたい
    # stderrに引数を全部出力する（もうやってるかも）
    # target/release/search_primer
    # -o, --output NAME   set output file name
    # -t, --thread THREAD number of threads to use for radix sort. default value
    #                     is 8.
    # -a, --threshold THRESHOLD
    #                     threshold of occurence. default value is 1000.
    # -m, --margin_size MARGIN_SIZE
    #                     margin between l and r segments. default value is 0.
    # -b, --binary        outputs binary file
    # -r, --only-num      outputs only total number of lr-tuple.
    # -h, --help          print this help menu
    input:
        reads=f"ngs_reads/{input_file_base}.part_{{sample}}.fasta"
    output:
        lr_tuples=f"lr_tuples/{threshold_zfill}_m{margin_size}/{{sample}}.bin",
        log_file = f"log/rule_count_lr_tuple/{threshold_zfill}_m{margin_size}_{{sample}}.log"
    params:
        threshold=threshold,
        threshold_zfill=threshold_zfill,
        margin_size=margin_size,
    resources:
        mem_mb=1000*24*6,
    threads: 6
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/count_lr_tuple/${{DATE_TIME}}_${{JOB_ID}}.csv"
        mkdir -p log/each_job/count_lr_tuple
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "count_lr_tuple,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        mkdir -p lr_tuples/{params.threshold_zfill}_m{params.margin_size}
        echo "Counting lr-tuple started: $(date)" > {output.log_file}
        scripts/search_primer {input.reads} -o {output.lr_tuples} -t {threads} -a {params.threshold} -m {params.margin_size} -b
        echo "Counting lr-tuple end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """


rule lr_tuple_binary_merge_and_split:
    input:
        lr_tuples=expand(f"lr_tuples/{threshold_zfill}_m{margin_size}/{{sample}}.bin", sample=ngs_read_indice),
    output:
        lr_tuples_unique=expand(f"lr_tuples_unique/{threshold_zfill}_m{margin_size}/{threshold_zfill}_{{sample}}.bin", sample=lr_tuple_indice),
        log_file = f"log/rule_lr_tuple_binary_merge_and_split/{threshold_zfill}_m{margin_size}.log",
    params:
        merged_file=f"temp/merged_lr_tuples_{threshold_zfill}.bin",
        margin_size=margin_size,
    resources:
        mem_mb=1000*8*4,
    threads: 4
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "lr_tuple_binary_merge_and_split,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p lr_tuples_unique temp
        # 各入力ファイルに対して -i オプションを付けてマージコマンドを構成
        merge_cmd=$(echo -n 'scripts/u128_binary_merge'; for f in {input.lr_tuples}; do echo -n " -i $f"; done; echo -n " -o {params.merged_file}")
        echo "Merging and spliting lr-tuple started: $(date)" > {output.log_file}
        bash -c "$merge_cmd"

        # マージされたファイルを指定された数に分割する
        mkdir -p lr_tuples_unique/{threshold_zfill}_m{params.margin_size}
        scripts/u128_binary_split -i {params.merged_file} -n {lr_tuple_part_size} -o lr_tuples_unique/{threshold_zfill}_m{params.margin_size}/{threshold_zfill}

        # 中間マージファイルを削除
        rm {params.merged_file}
        echo "Merging and spliting lr-tuple end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """


rule primer3_caller:
    #    $ ./target/release/primer3_caller -h
    #    Usage: ./target/release/primer3_caller FILE 
    #
    #    Options:
    #    -h, --help          print this help menu
    #    -t, --thread THREAD number of thread to use for radix sort. default value
    #                        is 8.
    #    -c, --config CONFIG config file for primer3_core.
    #    -o, --output OUTPUT output file name for primer3 results
    #    -m, --tmpfile TEMP  set temporary file name prefix
    input:
        lr_tuples=f"lr_tuples_unique/{threshold_zfill}_m{margin_size}/{threshold_zfill}_{{sample}}.bin"
    output:
        primer3_out=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{threshold_zfill}_{{sample}}.primer3_out",
        log_file = f"log/rule_primer3_caller/{threshold_zfill}_m{margin_size}_{{sample}}.log",
    params:
        primer3_config_display_name=primer3_config_display_name,
        primer3_config_path=primer3_config_path,
        margin_size=margin_size,
    resources:
        mem_mb=1000*8*8,
    threads: 8
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/primer3_caller/${{DATE_TIME}}_${{JOB_ID}}.csv"
        mkdir -p log/each_job/primer3_caller
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "primer3_caller,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p results_of_primer3_{params.primer3_config_display_name}_m{params.margin_size}/{threshold_zfill}
        echo "Running primer3 started: $(date)" > {output.log_file}
        scripts/primer3_caller {input.lr_tuples} -o {output.primer3_out} -c {params.primer3_config_path} -t {threads}
        echo "Running primer3 end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule results_of_primer3_to_fasta:
    input:
        primer3_out=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{threshold_zfill}_{{sample}}.primer3_out"
    output:
        fasta=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta/{threshold_zfill}/{threshold_zfill}_{{sample}}.fa",
        log_file = f"log/rule_results_of_primer3_to_fasta/{threshold_zfill}_m{margin_size}_{{sample}}.log",
    params:
        fasta_dir = f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta/{threshold_zfill}",
        primer3_result_parser_path = primer3_result_parser_path
    resources:
        mem_mb=1000*16*8,
    threads: 4
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/primer3_to_fasta/${{DATE_TIME}}_${{JOB_ID}}.csv"
        mkdir -p log/each_job/primer3_to_fasta
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "results_of_primer3_to_fasta,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        mkdir -p {params.fasta_dir}
        export PATH=/home/harazono/miniconda3/bin:$PATH
        mkdir -p log/rule_results_of_primer3_to_fasta
        echo "Running primer3 result parser started: $(date)" > {output.log_file}
        if [ ! -s {input.primer3_out} ]; then
            echo "WARNING: Input file is empty, creating empty output: $(date)" >> {output.log_file}
            touch {output.fasta}
            exit 0
        fi
        python3 {primer3_result_parser_path} {input.primer3_out} --fasta -o {output.fasta}
        echo "Running primer3 result parser end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule results_of_primer3_to_json:
    input:
        primer3_out=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{threshold_zfill}_{{sample}}.primer3_out"
    output:
        json=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_json/{threshold_zfill}/{threshold_zfill}_{{sample}}.json",
        log_file = f"log/rule_results_of_primer3_to_json/{threshold_zfill}_m{margin_size}_{{sample}}.log",
    params:
        json_dir = f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_json/{threshold_zfill}",
        primer3_result_parser_path = primer3_result_parser_path
    resources:
        mem_mb=1000*16*8,
    threads: 4
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/primer3_to_json/${{DATE_TIME}}_${{JOB_ID}}.csv"
        mkdir -p log/each_job/primer3_to_json
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "results_of_primer3_to_json,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        mkdir -p {params.json_dir}
        export PATH=/home/harazono/miniconda3/bin:$PATH
        mkdir -p log/rule_results_of_primer3_to_json
        echo "Running primer3 result parser started: $(date)" > {output.log_file}
        if [ ! -s {input.primer3_out} ]; then
            echo "WARNING: Input file is empty, creating empty output: $(date)" >> {output.log_file}
            echo "[]" > {output.json}
            exit 0
        fi
        python3 {primer3_result_parser_path} {input.primer3_out} -o {output.json}
        echo "Running primer3 result parser end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """


rule reduce_duplicated_primers:
    input:
        fasta=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta/{threshold_zfill}/{threshold_zfill}_{{sample}}.fa",
    output:
        fasta=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta_unique/{threshold_zfill}/{threshold_zfill}_{{sample}}.fa",
        log_file = f"log/rule_reduce_duplicated_primers/{threshold_zfill}_m{margin_size}_{{sample}}.log",
    params:
        fasta_dir = f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta_unique/{threshold_zfill}",
        fasta_prefix = f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta_unique/{threshold_zfill}/{threshold_zfill}",
        lr_tuple_part_size = lr_tuple_part_size,
    resources:
        mem_mb=1000*16*8,
    threads: 4
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "reduce_duplicated_primers,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p {params.fasta_dir}
        mkdir -p log/rule_reduce_duplicated_primers
        echo "Running reduce_duplicated_primers started: $(date)" > {output.log_file}
        if [ ! -s {input.fasta} ]; then
            echo "WARNING: Input file is empty, creating empty output: $(date)" >> {output.log_file}
            touch {output.fasta}
            exit 0
        fi
        python3 scripts/reduce_duplicated_primers.py {input.fasta} {params.fasta_prefix} {params.lr_tuple_part_size}
        echo "Running reduce_duplicated_primers end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """





rule cross_reaction_check_for_each_database:
    input:
        primer_fasta=f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_fasta_unique/{threshold_zfill}/{threshold_zfill}_{{sample}}.fa",
    output:
        non_cross_reactive_primer=f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{{sample}}/each_database_results/{{dbname}}_non_cross_reactive_primers.txt",
    params:
        output_dir=f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{{sample}}/each_database_results/",
        blast_db=f"/usr/local/db/blast/ncbi/v5/{{dbname}}",
        dbname = f"{{dbname}}",
        log_dir = directory(f"log/rule_cross_reaction_check_for_each_database/{threshold_zfill}_m{margin_size}/{{sample}}"),
        taxon_ids=taxon_ids,
        sample = f"{{sample}}",
    resources:
        mem_mb=1000*4*8,
        time=90*60,
    threads: 8
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/cross_reaction_check/{params.sample}/${{DATE_TIME}}_${{JOB_ID}}.csv"
        mkdir -p log/each_job/cross_reaction_check/{params.sample}
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "cross_reaction_check,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        export BLASTDB=/usr/local/db/blast/ncbi/v5/
        mkdir -p {params.output_dir}
        mkdir -p {params.log_dir}
        echo "Running cross_reaction_check_for_each_database started: $(date)" > {params.log_dir}/{params.dbname}.log
        if [ ! -s {input.primer_fasta} ]; then
            echo "WARNING: Input file is empty, creating empty output: $(date)" >> {params.log_dir}/{params.dbname}.log
            touch {output.non_cross_reactive_primer}
            exit 0
        fi
        dbinfo >> {params.log_dir}/{params.dbname}.log
        scripts/find_cross_reactive_primers -o {output.non_cross_reactive_primer} -r {params.blast_db} -p {input.primer_fasta} -T {threads} -t {params.taxon_ids}
        echo  "" >> {params.log_dir}/{params.dbname}.log
        echo "Running cross_reaction_check_for_each_database end:     $(date)" >> {params.log_dir}/{params.dbname}.log
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """






rule choose_non_cross_reactive_primers_001:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/001/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/001/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_001,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """


rule choose_non_cross_reactive_primers_002:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/002/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/002/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_002,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_003:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/003/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/003/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_003,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_004:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/004/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/004/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_004,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_005:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/005/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/005/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_005,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_006:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/006/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/006/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_006,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_007:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/007/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/007/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_007,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_008:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/008/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/008/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_008,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_009:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/009/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/009/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_009,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_010:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/010/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/010/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_010,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """

rule choose_non_cross_reactive_primers_011:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/011/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/011/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_011,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_012:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/012/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/012/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_012,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_013:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/013/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/013/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_013,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_014:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/014/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/014/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_014,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_015:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/015/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/015/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_015,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_016:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/016/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/016/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_016,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_017:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/017/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/017/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_017,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_018:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/018/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/018/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_018,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_019:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/019/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/019/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_019,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """
rule choose_non_cross_reactive_primers_020:
    input:
        expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/020/each_database_results/{{dbname}}_non_cross_reactive_primers.txt", dbname=tgt_db_names),
    output:
        f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/020/non_cross_reactive_primers.txt"
    resources:
        mem_mb=1000*8,
        time=90*60,
    threads: 2
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "choose_non_cross_reactive_primers_020,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        python3 scripts/choose_non_cross_reactive_primers.py {input} {output}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """


rule list_non_cross_reactive_primer_information:
    input:
        primer_ids = expand(f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/{{sample}}/non_cross_reactive_primers.txt", sample=blast_check_indice),
        json_files = expand(f"results_of_primer3_{primer3_config_display_name}_m{margin_size}_json/{threshold_zfill}/{threshold_zfill}_{{sample}}.json", sample=lr_tuple_indice),
    output:
        output_file = f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/non_cross_reactive_primers.tsv",
        log_file = f"log/rule_list_non_cross_reaction_primer_information/{threshold_zfill}_m{margin_size}.log",
    params:
        output_dir = f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}",
    resources:
        mem_mb=1000*8*4,
    threads: 4
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "list_non_cross_reactive_primer_information,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        export PATH=/home/harazono/miniconda3/bin:$PATH
        export LD_LIBRARY_PATH=~/miniconda3/pkgs/libffi-3.3-he6710b0_2/lib/:$LD_LIBRARY_PATH
        mkdir -p {params.output_dir}
        mkdir -p log/rule_list_non_cross_reaction_primer_information
        echo "Running list_non_cross_reaction_primer_information started: $(date)" > {output.log_file}
         python3 scripts/get_primers_from_primer_id.py --primer_id_files {input.primer_ids} --primer_info_json {input.json_files} --output {output.output_file}
        echo "Running list_non_cross_reaction_primer_information end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """




rule extract_amplicon:
    input:
        tsv = f"results_of_cross_reaction_check_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/non_cross_reactive_primers.tsv",
    output:
        fasta = f"results_of_extraction_of_amplicon_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}/amplicon_2000.fasta",
        log_file = f"log/rule_extract_amplicon/{threshold_zfill}_m{margin_size}.log",
    params:
        out_dir = f"results_of_extraction_of_amplicon_{primer3_config_display_name}_m{margin_size}/{threshold_zfill}",
        tgt_sequence_filename = f"ngs_reads/{input_file_base}.part_{ngs_read_indice[0]}.fasta"
    resources:
        mem_mb=1000*8*12,
    threads: 12
    shell:
        """
        mkdir -p log/each_job
        JOB_ID="${{JOB_ID:-LOCAL}}"
        DATE_TIME=$(date +%Y%m%d-%H%M%S)
        LOG_FILE="log/each_job/${{DATE_TIME}}_${{JOB_ID}}.csv"
        START_TIME=$(date)
        START_UNIX=$(date +%s)
        echo -n "extract_amplicon,${{JOB_ID}},${{START_TIME}},${{START_UNIX}}" > "${{LOG_FILE}}"
        mkdir -p {params.out_dir}
        mkdir -p log/rule_extract_amplicon
        echo "Running extract_amplicon started: $(date)" > {output.log_file}
        {extract_amplicon_path} -r {params.tgt_sequence_filename} -l 2000 -T 12 -t {input.tsv} -o {output.fasta}
        echo "Running extract_amplicon end:     $(date)" >> {output.log_file}
        END_TIME=$(date)
        END_UNIX=$(date +%s)
        echo ",${{END_TIME}},${{END_UNIX}}" >> "${{LOG_FILE}}"
        """




